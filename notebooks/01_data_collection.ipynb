{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5989a74",
   "metadata": {},
   "source": [
    "# Task 1: Data Ingestion and Data Preprocessing\n",
    "\n",
    "This notebook demonstrates the process of collecting and preparing Amharic e-commerce data from multiple Ethiopian-based Telegram channels. The workflow includes channel selection, data scraping, preprocessing, and storage for downstream entity extraction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab72ac5",
   "metadata": {},
   "source": [
    "## 1. Channel Selection\n",
    "\n",
    "We select at least 5 active Ethiopian e-commerce Telegram channels to maximize data diversity for fine-tuning. Example channels:\n",
    "- @EthiopianDeals\n",
    "- @AddisMarket\n",
    "- @ShegerBargains\n",
    "- @EthioShop\n",
    "- @BahirDarBazaar\n",
    "\n",
    "(Replace with actual channel usernames as needed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c99b6",
   "metadata": {},
   "source": [
    "## 2. Telegram Scraper Setup\n",
    "\n",
    "We use a custom Telegram scraper (e.g., Telethon or Pyrogram) to connect and fetch messages, images, and documents in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f57daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: telethon in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (1.40.0)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: pyaes in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from telethon) (1.6.1)\n",
      "Requirement already satisfied: rsa in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from telethon) (4.9.1)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: pyaes in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from telethon) (1.6.1)\n",
      "Requirement already satisfied: rsa in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from telethon) (4.9.1)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "  Using cached numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from rsa->telethon) (0.6.1)\n",
      "Using cached pandas-2.3.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ashe/Projects/10academy/Amharic-E-commerce-Data-Extractor/.venv/lib/python3.13/site-packages (from rsa->telethon) (0.6.1)\n",
      "Using cached pandas-2.3.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Downloading numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[?25l   \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading numpy-2.3.1-cp313-cp313-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m149.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:05\u001b[0m:07\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m149.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (if not already installed)\n",
    "!pip install telethon pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00e0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from telethon.sync import TelegramClient\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c84854",
   "metadata": {},
   "source": [
    "### 2.1. Connect to Telegram API\n",
    "\n",
    "Set up the Telegram client using your API credentials. Ensure you have a valid API ID and hash from https://my.telegram.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dc6e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempt 1 at connecting failed: TimeoutError: \n",
      "Attempt 2 at connecting failed: TimeoutError: \n",
      "Attempt 2 at connecting failed: TimeoutError: \n",
      "Invalid code. Please try again.\n",
      "Invalid code. Please try again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in successfully as Ashe; remember to not break the ToS or you will risk an account ban!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<telethon.client.telegramclient.TelegramClient at 0x7764d88e56a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from telethon import TelegramClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load credentials from environment variables\n",
    "api_id = os.getenv('TELEGRAM_API_ID')\n",
    "api_hash = os.getenv('TELEGRAM_API_HASH')\n",
    "phone = os.getenv('TELEGRAM_PHONE')\n",
    "\n",
    "client = TelegramClient('session_name', api_id, api_hash)\n",
    "await client.start(phone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15dd88",
   "metadata": {},
   "source": [
    "### 2.2. Fetch Messages from Selected Channels\n",
    "\n",
    "We fetch recent messages, including text, images, and documents, from the selected channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb14020",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m raw_data = []\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclient\u001b[49m.iter_messages(channel, limit=\u001b[32m1000\u001b[39m):\n\u001b[32m     15\u001b[39m         data = {\n\u001b[32m     16\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mchannel\u001b[39m\u001b[33m'\u001b[39m: channel,\n\u001b[32m     17\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: message.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mdocument_url\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     22\u001b[39m         }\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message.media, MessageMediaPhoto):\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "from telethon.tl.types import MessageMediaPhoto, MessageMediaDocument\n",
    "\n",
    "channels = [\n",
    "    'EthiopianDeals',\n",
    "    'AddisMarket',\n",
    "    'ShegerBargains',\n",
    "    'EthioShop',\n",
    "    'BahirDarBazaar'\n",
    "]\n",
    "\n",
    "raw_data = []\n",
    "\n",
    "for channel in channels:\n",
    "    async for message in client.iter_messages(channel, limit=1000):\n",
    "        data = {\n",
    "            'channel': channel,\n",
    "            'text': message.text,\n",
    "            'timestamp': message.date,\n",
    "            'views': message.views,\n",
    "            'image_url': None,\n",
    "            'document_url': None\n",
    "        }\n",
    "        if isinstance(message.media, MessageMediaPhoto):\n",
    "            data['image_url'] = 'downloaded_image_path'  # Implement download logic\n",
    "        if isinstance(message.media, MessageMediaDocument):\n",
    "            data['document_url'] = 'downloaded_document_path'  # Implement download logic\n",
    "        raw_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862cb51",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "We preprocess the collected text data by normalizing, tokenizing, and handling Amharic-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_amharic_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = re.sub(r'[፡።:]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "for item in raw_data:\n",
    "    item['text'] = normalize_amharic_text(item['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ef70c",
   "metadata": {},
   "source": [
    "## 4. Structuring and Saving the Data\n",
    "\n",
    "We structure the data into a DataFrame, separating metadata from message content, and save it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(raw_data)\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "df.to_json('data/raw/telegram_data.json', orient='records', force_ascii=False)\n",
    "df.to_csv('data/raw/telegram_data.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c362a36f",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "- Connected to at least 5 Ethiopian e-commerce Telegram channels.\n",
    "- Ingested messages, images, and documents in real time.\n",
    "- Preprocessed Amharic text for downstream tasks.\n",
    "- Saved structured data for further analysis and entity extraction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
